{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(x, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import fnmatch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from datamodule import Datamodule\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from params import RANDOM_SEED, LocationConfig, CreateDataConfig, TrainingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_data_directories(path):\n",
    "    Path().mkdir(exist_ok=True, parents=True)\n",
    "    Path(path + 'train').mkdir(exist_ok=True, parents=True)\n",
    "    Path(path + 'test').mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    \n",
    "def get_short_video_name(videoNames):\n",
    "    ShortVideoName = []\n",
    "    for videoName in videoNames.values:\n",
    "        ShortVideoName.append(videoName.split('.')[0])\n",
    "    return ShortVideoName\n",
    "\n",
    "def create_mean_video_name_df(df):\n",
    "    cols = ['ValueExtraversion','ValueAgreeableness','ValueConscientiousness','ValueNeurotisicm','ValueOpenness','ShortVideoName']\n",
    "    grouped_df = df[cols].groupby('ShortVideoName')\n",
    "    mean_df = grouped_df.mean()\n",
    "    mean_df = mean_df.reset_index()\n",
    "    return mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26604/26604 [00:05<00:00, 4971.94it/s]\n"
     ]
    }
   ],
   "source": [
    "create_new_data_directories(LocationConfig.shuffle_data)\n",
    "\n",
    "df = pd.read_csv(LocationConfig.labels + 'bigfive_labels.csv')\n",
    "\n",
    "df['ShortVideoName'] = get_short_video_name(df['VideoName'])\n",
    "\n",
    "mean_df = create_mean_video_name_df(df)\n",
    "mean_df.to_csv(LocationConfig.labels + 'bigfive_labels_mean.csv')\n",
    "mean_df = mean_df.set_index('ShortVideoName')\n",
    "\n",
    "X_train, X_test = train_test_split(\n",
    "    np.array(mean_df.index), \n",
    "    test_size=CreateDataConfig.test_size_ratio,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "images_dict_train = {'X':[], 'Y':[]}\n",
    "images_dict_test = {'X':[], 'Y':[]}\n",
    "total_files = len(fnmatch.filter(os.listdir(LocationConfig.crop_data), '*.jpg'))\n",
    "for image_path in tqdm(Path(LocationConfig.crop_data).glob('*.jpg'), total=total_files):\n",
    "    X = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE) \n",
    "    X = np.expand_dims(X, axis=2) \n",
    "    image_group = image_path.name.split('.')[0]\n",
    "    image_no = image_path.name.split('.')[2][-5:]\n",
    "    Y = mean_df.loc[image_group].values\n",
    "    if CreateDataConfig.classification:\n",
    "        Y = list(np.where(Y>CreateDataConfig.Y_threshold, 1, 0))\n",
    "\n",
    "    if image_group in X_test:\n",
    "        images_dict_test['X'].append(X)\n",
    "        images_dict_test['Y'].append(Y)\n",
    "    else:\n",
    "        images_dict_train['X'].append(X)\n",
    "        images_dict_train['Y'].append(Y)\n",
    "\n",
    "with open(LocationConfig.shuffle_data + 'train/train.pickle', 'wb') as handle:\n",
    "    pickle.dump(images_dict_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(LocationConfig.shuffle_data + 'test/test.pickle', 'wb') as handle:\n",
    "    pickle.dump(images_dict_test, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: new_data/train/train.pickle\n",
      "file: new_data/test/test.pickle\n"
     ]
    }
   ],
   "source": [
    "train_data_path = Path(LocationConfig.new_data + 'train')\n",
    "test_data_path = Path(LocationConfig.new_data + 'test')\n",
    "dm = Datamodule(\n",
    "        batch_size=TrainingConfig.batch_size,\n",
    "        train_dir=train_data_path,\n",
    "        val_dir=test_data_path,\n",
    "        )\n",
    "# dm.setup(val_only=True)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:02<00:00, 85.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56551927 0.285961   0.40653195 0.41715226 0.2837641 ]\n",
      "0.39178571428571424\n",
      "test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 72.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52679211 0.3142343  0.40442206 0.41275567 0.28363975]\n",
      "0.38836877931214175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('train:')\n",
    "acc_class_global_0 = 0\n",
    "i=0\n",
    "for batch in tqdm(dm.train_dataloader()):\n",
    "    X, Y = batch['normalized'], batch['label']\n",
    "    Y_pred = np.zeros_like(Y)\n",
    "    acc_class_0 = np.sum(Y_pred == np.array(Y), axis=0) / len(Y)\n",
    "    acc_class_global_0 += acc_class_0\n",
    "    i+=1\n",
    "acc_class_global_0 /= i\n",
    "print(acc_class_global_0)\n",
    "print(acc_class_global_0.mean())\n",
    "\n",
    "print('test:')\n",
    "acc_class_global_0 = 0\n",
    "i=0\n",
    "for batch in tqdm(dm.val_dataloader()):\n",
    "    X, Y = batch['normalized'], batch['label']\n",
    "    Y_pred = np.zeros_like(Y)\n",
    "    acc_class_0 = np.sum(Y_pred == np.array(Y), axis=0) / len(Y)\n",
    "    acc_class_global_0 += acc_class_0\n",
    "    i+=1\n",
    "acc_class_global_0 /= i\n",
    "print(acc_class_global_0)\n",
    "print(acc_class_global_0.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
